{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_model_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pSI95M0tGrsIMlGZQnRFgI0kia4m3mXm",
      "authorship_tag": "ABX9TyOsmRtwkwjJcFcxaEYo5Ah+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongwoo1126/Colab/blob/master/Ch04.%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%A7%88%EC%9D%B4%EB%8B%9D%20%EC%8B%A4%EC%8A%B5/Chatbot_model_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "LcausLF_QyjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3138cdec-2f88-4866-c59d-5deb2a80ee00"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BFBKkIqQO_bo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰 불러오기\n",
        "with open('/content/drive/MyDrive/파이썬 데이터 과학 실습/file/chatbot_tokenizer.pickle', 'rb') as handle:\n",
        "  tokenizer = pickle.load(handle)\n",
        "\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "d5_COYiWQAg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22740b8-7a84-4126-f2af-60088c1b578c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7f1b081b1c10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "model = load_model('/content/drive/MyDrive/파이썬 데이터 과학 실습/file/chatbot_model.h5')\n",
        "model"
      ],
      "metadata": {
        "id": "AblyG907QZQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb4f2e4-b14c-4138-e182-471014bd139b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f1a8fb22390>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 생성 함수\n",
        "def sentence_generation(current_word):\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  while True:\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=20, padding='pre')\n",
        "\n",
        "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      # 만약 예측한 단어, 인덱스와 동일한 단어가 있다면\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    # 종료 체크\n",
        "    if word == '<end>':\n",
        "      break\n",
        "\n",
        "    # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    current_word = current_word + ' ' + word\n",
        "\n",
        "    #예측 단어를 문장에 저장\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word + ' --->' + sentence\n",
        "\n",
        "  return sentence\n",
        "  "
      ],
      "metadata": {
        "id": "j0-wtiMTQsqe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "print(sentence_generation('12시 땡!'))\n",
        "print(sentence_generation('코 막혀'))\n",
        "print(sentence_generation('무슨 말을 해야할까'))\n",
        "print(sentence_generation('안녕'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5DouMQYTGTA",
        "outputId": "b5ccfa7e-e82c-4c64-a03a-de9fe210a3c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12시 땡! ---> 하루가 또 가네요\n",
            "코 막혀 ---> 감기 조심하세요\n",
            "무슨 말을 해야할까 ---> 하고 싶은 말 다하세요\n",
            "안녕 ---> 안녕하세요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SswDlln5TZQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}